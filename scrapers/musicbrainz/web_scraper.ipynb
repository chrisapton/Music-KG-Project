{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import time  # Importing time for delay\n",
    "\n",
    "def get_artist_musicbrainz_url(artist_name):\n",
    "    \"\"\"Search for the artist on MusicBrainz and get the artist URL.\"\"\"\n",
    "    base_url = \"https://musicbrainz.org\"\n",
    "    search_url = f\"{base_url}/search?query={artist_name.replace(' ', '+')}&type=artist&method=indexed\"\n",
    "    try:\n",
    "        response = requests.get(search_url, headers={\"User-Agent\": \"YourAppName/1.0 (your-email@example.com)\"})\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the first search result link\n",
    "        artist_link = soup.select_one(\"table.tbl a\")\n",
    "        if artist_link:\n",
    "            return base_url + artist_link['href']\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching artist page: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove unnecessary characters and clean up text.\"\"\"\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '').strip()\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def scrape_wikipedia_summary(artist_url):\n",
    "    \"\"\"Scrape the Wikipedia summary from the artist's MusicBrainz page.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(artist_url, headers={\"User-Agent\": \"YourAppName/1.0 (your-email@example.com)\"})\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Adding a small delay after the request to ensure content has loaded\n",
    "        time.sleep(1)  # Wait for 1 second\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the Wikipedia section using the div with class \"wikipedia-extract-body\"\n",
    "        wiki_div = soup.find(\"div\", class_=\"wikipedia-extract-body wikipedia-extract-collapse\")\n",
    "        if wiki_div:\n",
    "            print(wiki_div)\n",
    "            # Extract all paragraphs separately and join them with proper spacing\n",
    "            paragraphs = wiki_div.find_all(\"p\")\n",
    "            summary_parts = []\n",
    "            for p in paragraphs:\n",
    "                # Extract the text from each paragraph\n",
    "                paragraph_text = p.get_text(separator=\" \", strip=True)\n",
    "                cleaned_text = clean_text(paragraph_text)\n",
    "                summary_parts.append(cleaned_text)\n",
    "\n",
    "            # Join all paragraphs into a single summary\n",
    "            full_summary = \" \".join(summary_parts)\n",
    "\n",
    "            # Remove any \"Continue reading at Wikipedia\" links or extra texts\n",
    "            if \"Continue reading at Wikipedia\" in full_summary:\n",
    "                full_summary = full_summary.split(\"Continue reading at Wikipedia\")[0].strip()\n",
    "\n",
    "            return full_summary\n",
    "        return \"N/A\"\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error scraping Wikipedia summary: {e}\")\n",
    "        return \"N/A\"\n",
    "\n",
    "def fetch_artist_details(artist_name):\n",
    "    \"\"\"Fetch the Wikipedia summary directly from the MusicBrainz artist page.\"\"\"\n",
    "    artist_url = get_artist_musicbrainz_url(artist_name)\n",
    "    if artist_url:\n",
    "        print(f\"Found artist page: {artist_url}\")\n",
    "        wikipedia_summary = scrape_wikipedia_summary(artist_url)\n",
    "        return {\"wikipedia_summary\": wikipedia_summary}\n",
    "    else:\n",
    "        print(\"Artist page not found.\")\n",
    "        return {\"wikipedia_summary\": \"N/A\"}\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process each JSONL file to extract song and artist details.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    # Parse the JSON line\n",
    "                    song_data = json.loads(line.strip())\n",
    "\n",
    "                    # Handle single and multiple artist formats\n",
    "                    artists = song_data.get(\"artist\")\n",
    "                    if isinstance(artists, str):\n",
    "                        artists = [artists]\n",
    "\n",
    "                    song_name = song_data.get(\"title\", \"N/A\")\n",
    "\n",
    "                    for artist_name in artists:\n",
    "                        # Fetch the Wikipedia summary\n",
    "                        artist_details = fetch_artist_details(artist_name)\n",
    "                        wikipedia_summary = artist_details.get(\"wikipedia_summary\", \"N/A\")\n",
    "\n",
    "                        print(f\"Title: {song_name}\")\n",
    "                        print(f\"Artist: {artist_name}\")\n",
    "                        print(f\"Wikipedia Summary: {wikipedia_summary}\")\n",
    "                        print(\"-\" * 50)\n",
    "                        break\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error: Invalid JSON line.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "\n",
    "# Base directory for files\n",
    "base_dir = '/Users/chrisapton/Desktop/Spring 2025/DSCI 558/Music-KG-Project/data/raw_data/'\n",
    "\n",
    "# Loop through pages 1 to 10\n",
    "for page_number in range(1, 11):\n",
    "    file_name = f'whosampled_tracks_2024_{page_number}.jsonl'\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "    process_file(file_path)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: whosampled_tracks_2024_1.jsonl\n",
      "https://musicbrainz.org/ws/2/recording/?query=recording%3A%22Like%20That%22%20AND%20%28artist%3A%22Future%22%20OR%20artist%3A%22Metro%20Boomin%22%20OR%20artist%3A%22Kendrick%20Lamar%22%29&fmt=json\n",
      "{'id': '3ee072c3-eb70-42a3-8bb4-474e3e27358b', 'score': 100, 'title': 'Like That', 'length': 76000, 'disambiguation': 'part of “Super Bowl LIX Hip‐Hop Dance Party” DJ‐mix', 'video': None, 'artist-credit': [{'joinphrase': ', ', 'name': 'Metro Boomin', 'artist': {'id': '59db3d82-86ea-451f-881f-dffc8ec387c9', 'name': 'Metro Boomin', 'sort-name': 'Metro Boomin', 'disambiguation': 'American record producer', 'aliases': [{'sort-name': 'Wayne, Leland Tyler', 'type-id': 'd4dcd0c0-b341-3612-a332-c0ce797b25cf', 'name': 'Leland Tyler Wayne', 'locale': None, 'type': 'Legal name', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Wayne, Leland', 'name': 'Leland Wayne', 'locale': None, 'type': None, 'primary': None, 'begin-date': None, 'end-date': None}]}}, {'joinphrase': ' & ', 'name': 'Kendrick Lamar', 'artist': {'id': '381086ea-f511-4aba-bdf9-71c753dc5077', 'name': 'Kendrick Lamar', 'sort-name': 'Lamar, Kendrick', 'disambiguation': 'US rapper', 'aliases': [{'sort-name': '켄드릭 라마', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': '켄드릭 라마', 'locale': 'ko', 'type': 'Artist name', 'primary': True, 'begin-date': None, 'end-date': None}, {'sort-name': 'OKLAMA', 'type-id': '1937e404-b981-3cb7-8151-4c86ebfc8d8e', 'name': 'OKLAMA', 'locale': None, 'type': 'Search hint', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'K‐Dot', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'K‐Dot', 'locale': None, 'type': 'Artist name', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'K. Duckworth', 'type-id': '1937e404-b981-3cb7-8151-4c86ebfc8d8e', 'name': 'K. Duckworth', 'locale': None, 'type': 'Search hint', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Duckworth, Kendrick Lamar', 'type-id': 'd4dcd0c0-b341-3612-a332-c0ce797b25cf', 'name': 'Kendrick Lamar Duckworth', 'locale': None, 'type': 'Legal name', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Kendrick Duckworth', 'type-id': '1937e404-b981-3cb7-8151-4c86ebfc8d8e', 'name': 'Kendrick Duckworth', 'locale': None, 'type': 'Search hint', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'K. Dot', 'type-id': '1937e404-b981-3cb7-8151-4c86ebfc8d8e', 'name': 'K. Dot', 'locale': None, 'type': 'Search hint', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'ケンドリック・ラマー', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'ケンドリック・ラマー', 'locale': 'ja', 'type': 'Artist name', 'primary': True, 'begin-date': None, 'end-date': None}]}}, {'name': 'Future', 'artist': {'id': '48262e82-db9f-4a92-b650-dfef979b73ec', 'name': 'Future', 'sort-name': 'Future', 'disambiguation': 'US rapper Nayvadius Cash', 'aliases': [{'sort-name': 'Meathead', 'name': 'Meathead', 'locale': None, 'type': None, 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Wilburn, Nayvadius', 'name': 'Nayvadius Wilburn', 'locale': None, 'type': None, 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Cash, Nayvadius DeMun', 'type-id': 'd4dcd0c0-b341-3612-a332-c0ce797b25cf', 'name': 'Nayvadius DeMun Cash', 'locale': None, 'type': 'Legal name', 'primary': None, 'begin-date': '2022-11', 'end-date': None}, {'sort-name': 'Future', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'Future', 'locale': 'en', 'type': 'Artist name', 'primary': True, 'begin-date': None, 'end-date': None}, {'sort-name': 'Wilburn, Nayvadius D.', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'Nayvadius D. Wilburn', 'locale': None, 'type': 'Artist name', 'primary': None, 'begin-date': None, 'end-date': '2022-11'}, {'sort-name': 'Cash, Nayvadius “Future”', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'Nayvadius “Future” Cash', 'locale': None, 'type': 'Artist name', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Cash, N.', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'N. Cash', 'locale': None, 'type': 'Artist name', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Cash, Nayvadius', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'Nayvadius Cash', 'locale': None, 'type': 'Artist name', 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Wilburn, Nayvadius Demun', 'type-id': 'd4dcd0c0-b341-3612-a332-c0ce797b25cf', 'name': 'Nayvadius Demun Wilburn', 'locale': None, 'type': 'Legal name', 'primary': None, 'begin-date': None, 'end-date': '2022-11'}]}}], 'first-release-date': '2025-01-31', 'releases': [{'id': '3347599b-bd96-43f8-89ef-aa32bf949d80', 'status-id': '4e304316-386d-3409-af2e-78857eec5cfe', 'count': 1, 'title': 'Super Bowl LIX Hip‐Hop Dance Party', 'status': 'Official', 'artist-credit': [{'name': 'Mannie Fresh', 'artist': {'id': '34dc70df-8b2c-4bb0-a132-0958671a509c', 'name': 'Mannie Fresh', 'sort-name': 'Mannie Fresh'}}], 'release-group': {'id': '3c111981-3ff6-4d63-bfee-a65f4e4414e7', 'type-id': 'f529b476-6e62-324f-b0aa-1f3e33d313fc', 'primary-type-id': 'f529b476-6e62-324f-b0aa-1f3e33d313fc', 'title': 'Super Bowl LIX Hip‐Hop Dance Party', 'primary-type': 'Album', 'secondary-types': ['DJ-mix'], 'secondary-type-ids': ['0d47f47a-3fe5-3d69-ac9d-d566c23968bf']}, 'track-count': 51, 'media': [{'position': 1, 'format': 'Digital Media', 'track': [{'id': 'a82f48eb-a8fb-45e9-81da-df1790eead48', 'number': '47', 'title': 'Like That', 'length': 76000}], 'track-count': 51, 'track-offset': 46}]}], 'isrcs': ['US23A9853192']}\n",
      "Found artist URL: https://musicbrainz.org/artist/48262e82-db9f-4a92-b650-dfef979b73ec (Attempt 1)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_artist_musicbrainz_url(artist_name):\n",
    "    \"\"\"Search for the artist on MusicBrainz and get the artist URL.\"\"\"\n",
    "    base_url = \"https://musicbrainz.org\"\n",
    "    search_url = f\"{base_url}/search?query={artist_name.replace(' ', '+')}&type=artist&method=indexed\"\n",
    "    attempts = 3  # Number of retries\n",
    "\n",
    "    for attempt in range(1, attempts + 1):\n",
    "        try:\n",
    "            response = requests.get(search_url, headers={\"User-Agent\": \"YourAppName/1.0 (your-email@example.com)\"})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find the first search result link\n",
    "            artist_link = soup.select_one(\"table.tbl a\")\n",
    "            if artist_link:\n",
    "                full_url = base_url + artist_link['href']\n",
    "                print(f\"Found artist URL: {full_url} (Attempt {attempt})\")\n",
    "                return full_url\n",
    "            \n",
    "            print(f\"Attempt {attempt}: No artist link found. Retrying...\")\n",
    "            time.sleep(1)  # Brief pause before retrying\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Attempt {attempt}: Error fetching artist page: {e}\")\n",
    "            time.sleep(1)  # Brief pause before retrying\n",
    "\n",
    "    # If all attempts fail, print the fetched page content for debugging\n",
    "    print(f\"Failed to retrieve artist URL after {attempts} attempts.\")\n",
    "    print(f\"Search URL: {search_url}\")\n",
    "    print(\"Page content:\")\n",
    "    print(response.text[:1000])  # Print the first 1000 characters to avoid overwhelming output\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_release_date(recording):\n",
    "    \"\"\"Extract the release date from a recording.\"\"\"\n",
    "    # Check for \"first-release-date\" field first\n",
    "    if 'first-release-date' in recording:\n",
    "        return recording['first-release-date']\n",
    "\n",
    "    # Fallback: Check inside the \"releases\" list\n",
    "    release_dates = []\n",
    "    if 'releases' in recording and recording['releases']:\n",
    "        for release in recording['releases']:\n",
    "            date = release.get('date', 'N/A')\n",
    "            if date != 'N/A':\n",
    "                release_dates.append(date)\n",
    "\n",
    "        # Sort by length and value to prioritize full dates (YYYY-MM-DD)\n",
    "        if release_dates:\n",
    "            return min(release_dates, key=lambda x: (len(x), x))\n",
    "\n",
    "    return \"N/A\"\n",
    "\n",
    "\n",
    "def get_genres(recording):\n",
    "    \"\"\"Extract the genres from a recording.\"\"\"\n",
    "    print(recording)\n",
    "    genres = set()\n",
    "\n",
    "    # Check for genres directly in the recording tags\n",
    "    if 'tags' in recording:\n",
    "        for tag in recording['tags']:\n",
    "            genres.add(tag['name'])\n",
    "\n",
    "    # Fallback: Check the release group for genres\n",
    "    if 'releases' in recording and recording['releases']:\n",
    "        for release in recording['releases']:\n",
    "            if 'release-group' in release and 'tags' in release['release-group']:\n",
    "                for tag in release['release-group']['tags']:\n",
    "                    genres.add(tag['name'])\n",
    "\n",
    "    # If no genres found, try to check the artist tags\n",
    "    if not genres and 'artist-credit' in recording:\n",
    "        for artist_credit in recording['artist-credit']:\n",
    "            artist = artist_credit.get('artist', {})\n",
    "            if 'tags' in artist:\n",
    "                for tag in artist['tags']:\n",
    "                    genres.add(tag['name'])\n",
    "\n",
    "    return list(genres)\n",
    "\n",
    "\n",
    "def scrape_wikipedia_summary_selenium(artist_url):\n",
    "    \"\"\"Scrape the Wikipedia summary from the artist's MusicBrainz page using Selenium.\"\"\"\n",
    "    try:\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "        # Path to your ChromeDriver\n",
    "        driver_path = '/Users/chrisapton/Desktop/Spring 2025/DSCI 558/chromedriver-mac-arm64/chromedriver'\n",
    "        service = Service(driver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        driver.get(artist_url)\n",
    "\n",
    "        try:\n",
    "            wiki_div = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'wikipedia-extract-body'))\n",
    "            )\n",
    "            summary = wiki_div.text.strip()\n",
    "\n",
    "            # Remove any \"Continue reading at Wikipedia\" text\n",
    "            if \"Continue reading at Wikipedia\" in summary:\n",
    "                summary = summary.split(\"Continue reading at Wikipedia\")[0].strip()\n",
    "\n",
    "            driver.quit()\n",
    "            return summary if summary else \"N/A\"\n",
    "        except Exception as e:\n",
    "            print(artist_url)\n",
    "            print(f\"Error finding Wikipedia summary: {e}\")\n",
    "\n",
    "            driver.quit()\n",
    "            return \"N/A\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error with Selenium: {e}\")\n",
    "        return \"N/A\"\n",
    "\n",
    "def fetch_song_details(song_name, artists):\n",
    "    \"\"\"Fetch song release date and genre from MusicBrainz.\"\"\"\n",
    "    # Join artist names with \" AND \" for the query\n",
    "    artist_query = \" OR \".join([f'artist:\"{artist}\"' for artist in artists])\n",
    "    # Combine the title and artist queries\n",
    "    query = f'recording:\"{song_name}\" AND ({artist_query})'\n",
    "    # Encode the query to make it URL-safe\n",
    "    encoded_query = requests.utils.quote(query)\n",
    "    # Construct the full URL\n",
    "    url = f'https://musicbrainz.org/ws/2/recording/?query={encoded_query}&fmt=json'\n",
    "    print(url)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"YourAppName/1.0 (your-email@example.com)\"})\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if 'recordings' in data and data['recordings']:\n",
    "            for recording in data['recordings']:\n",
    "                title = recording.get('title', 'N/A')\n",
    "                artist_credit = recording.get('artist-credit', [])\n",
    "\n",
    "                # Extract all artist names from the recording\n",
    "                recording_artists = [credit.get('name', 'N/A').lower() for credit in artist_credit]\n",
    "\n",
    "                # Check if all given artists are present in the recording\n",
    "                if all(artist.lower() in recording_artists for artist in artists) and song_name.lower() in title.lower():\n",
    "                    release_date = get_release_date(recording)\n",
    "                    genres = get_genres(recording)\n",
    "                    return {\n",
    "                        \"title\": title,\n",
    "                        \"artist\": [artist['name'] for artist in artist_credit],\n",
    "                        \"release_date\": release_date,\n",
    "                        \"genres\": genres\n",
    "                    }\n",
    "                else: \n",
    "                    print(\"can't find all artists: approx search\")\n",
    "                    release_date = get_release_date(recording)\n",
    "                    genres = get_genres(recording)\n",
    "                    return {\n",
    "                        \"title\": title,\n",
    "                        \"artist\": [artist['name'] for artist in artist_credit],\n",
    "                        \"release_date\": release_date,\n",
    "                        \"genres\": genres\n",
    "                    }\n",
    "        return {\"title\": song_name, \"artist\": \", \".join(artists), \"release_date\": \"N/A\", \"genres\": \"N/A\"}\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching song details: {e}\")\n",
    "        return {\"title\": song_name, \"artist\": \", \".join(artists), \"release_date\": \"N/A\", \"genres\": \"N/A\"}\n",
    "\n",
    "def fetch_artist_wikipedia(artist_name):\n",
    "    \"\"\"Fetch Wikipedia summary for a given artist.\"\"\"\n",
    "    artist_url = get_artist_musicbrainz_url(artist_name)\n",
    "    wikipedia_summary = scrape_wikipedia_summary_selenium(artist_url)\n",
    "    return wikipedia_summary\n",
    "\n",
    "def fetch_artist_genres(artist_name):\n",
    "    \"\"\"\n",
    "    Fetches the top genres of an artist from the MusicBrainz API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Search for the artist to get their MusicBrainz ID\n",
    "        search_url = f'https://musicbrainz.org/ws/2/artist/?query={artist_name}&fmt=json'\n",
    "        search_response = requests.get(search_url, headers={\"User-Agent\": \"YourAppName/1.0 (your-email@example.com)\"})\n",
    "        search_response.raise_for_status()\n",
    "        search_data = search_response.json()\n",
    "        \n",
    "        # Get the first matching artist ID\n",
    "        if search_data['artists']:\n",
    "            artist_id = search_data['artists'][0]['id']\n",
    "        else:\n",
    "            print(f\"No artist found for {artist_name}\")\n",
    "            return []\n",
    "\n",
    "        # Step 2: Get the artist details using the ID\n",
    "        artist_url = f'https://musicbrainz.org/ws/2/artist/{artist_id}?inc=tags&fmt=json'\n",
    "        response = requests.get(artist_url, headers={\"User-Agent\": \"YourAppName/1.0 (your-email@example.com)\"})\n",
    "        response.raise_for_status()\n",
    "        artist_data = response.json()\n",
    "\n",
    "        # Extract genres from the tags field\n",
    "        genres = [tag['name'] for tag in artist_data.get('tags', [])]\n",
    "\n",
    "        # Return top 3-4 genres if available\n",
    "        return genres[:4] if genres else []\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching artist genres: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process each JSONL file to extract song and artist details.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    song_data = json.loads(line.strip())\n",
    "                    artists = song_data.get(\"artist\")\n",
    "                    if isinstance(artists, str):\n",
    "                        artists = [artists]\n",
    "\n",
    "                    song_name = song_data.get(\"title\", \"N/A\")\n",
    "\n",
    "                    artist_details = fetch_song_details(song_name, artists)\n",
    "                    wikipedia_summaries = list(map(fetch_artist_wikipedia, artists))\n",
    "\n",
    "                    if len(artist_details['genres']) == 0:\n",
    "                        for artist in artists:\n",
    "                            artist_details['genres'].extend(fetch_artist_genres(artist))\n",
    "\n",
    "                        artist_details['genres'] = list(set(artist_details['genres']))\n",
    "\n",
    "                    print(f\"Title: {artist_details['title']}\")\n",
    "                    print(f\"Artist: {artist_details['artist']}\")\n",
    "                    print(f\"Release Date: {artist_details['release_date']}\")\n",
    "                    print(f\"Genres: {artist_details['genres']}\")\n",
    "                    print(f\"Wikipedia Summary: {wikipedia_summaries}\")\n",
    "                    print(\"-\" * 50)\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error: Invalid JSON line.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "\n",
    "# Base directory for files\n",
    "base_dir = '/Users/chrisapton/Desktop/Spring 2025/DSCI 558/Music-KG-Project/data/raw_data/'\n",
    "\n",
    "# Loop through pages 1 to 10\n",
    "for page_number in range(1, 11):\n",
    "    file_name = f'whosampled_tracks_2024_{page_number}.jsonl'\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "    process_file(file_path)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
